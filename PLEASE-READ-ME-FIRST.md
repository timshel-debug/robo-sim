Hi Champion Data,

Full disclosure (and in the interests of radical honesty): this repo is AI-assisted to the hilt. The implementation, tests, and even the “likely interview questions & answers” doc were produced with heavy LLM involvement. If you find yourself thinking, “This feels suspiciously well-structured for a two-hour take-home,” you are not imagining things.

A bit of context on why I’ve done it this way: I don’t really believe in take-home tests in principle. Not because I can’t do them, but because they often:

* Shift meaningful evaluation into unpaid time (and disproportionately penalise people with families or heavy workloads).
* Over-index on “free time and polish” rather than day-to-day engineering judgement and collaboration.
* Incentivise performative architecture and over-testing that wouldn’t be the right trade-off in real delivery.
* Create weird comparability issues (some people use tools/assistants, some don’t; some spend 2 hours, some spend 20).

That said: if I’m going to do one, I’m going to do it on my terms—meaning I’ll treat it like modern engineering work. That includes using the tools that are now standard in the industry, being explicit about trade-offs, and aiming for a clean, testable, well-documented result within the timebox.

If you’d like, I’m very happy to talk through how I use AI in practice in a way that’s genuinely useful without turning it into an “autopilot that ships nonsense.” Concretely: how I set constraints up front, how I validate outputs (tests, edge cases, invariants), where I draw the line on what must be human-owned, and how I use AI to accelerate the boring parts while keeping correctness and judgement firmly on my side of the keyboard.

In short: yes, I used AI aggressively—and I did it deliberately. The interesting part isn’t “can I type a toy robot simulator from memory,” it’s whether I can produce a correct, maintainable solution, quickly, with good judgement. That’s what I’m optimising for here.

Regards,
Dave
